{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37c70600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %uv pip install ipykernal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52424380",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")\n",
    "%pwd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de570c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7932839a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract data from pdf file.\n",
    "def load_pdf_file(data):\n",
    "    loader = DirectoryLoader(data, glob=\"*.pdf\", loader_cls=PyPDFLoader)\n",
    "    documents = loader.load()\n",
    "    return documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d36c0338",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd\n",
    "extracted_data = load_pdf_file(data=\"Data/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6caf65d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into chunks.\n",
    "def text_split(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n",
    "    text_chunks = text_splitter.split_documents(extracted_data)\n",
    "    return text_chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "732618f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all page_content into a single string\n",
    "text_chunks = text_split(extracted_data)\n",
    "print(\"length of text chunks\", len(text_chunks))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ca937ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78cab114",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_hugging_face_embeddings():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    return embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc167b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = download_hugging_face_embeddings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d16471be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_result = embeddings.embed_query(\"What is Langchain?\")\n",
    "# print(\"Length of query_result:\", len(query_result))\n",
    "# query_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a56cd6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2f82e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = os.environ.get(\"PINECONE_API_KEY\")\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e25e75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pinecone.grpc import PineconeGRPC as Pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "from pydantic import SerializationInfo\n",
    "\n",
    "# Check if PINECONE_API_KEY is set\n",
    "api_key = os.environ.get(\"PINECONE_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"PINECONE_API_KEY environment variable not set. Please set it in your .env file or environment.\")\n",
    "\n",
    "pc = Pinecone(api_key=api_key)\n",
    "index_name = \"medicalchatbot\"\n",
    "\n",
    "\n",
    "if not pc.has_index(index_name):\n",
    "    pc.create_index(name=index_name, dimension=384, metric=\"cosine\", \n",
    "                    spec=ServerlessSpec(cloud=\"aws\", \n",
    "                                   region=\"us-east-1\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2bf52a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "docsearch = PineconeVectorStore.from_documents(documents=text_chunks, embedding=embeddings, index_name=index_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6091ebc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for loading existing index.\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "# Embed each chunk and upsert the embeddings in to your pinecone index.\n",
    "docsearch = PineconeVectorStore.from_existing_index(embedding=embeddings, index_name=index_name)\n",
    "docsearch\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4bf14eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check as docsearch to fetch relevent docs.\n",
    "retriever = docsearch.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":3})\n",
    "retrived_docs = retriever.invoke(\"What is Acne ?\")\n",
    "retrived_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6564de78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now setup llm to pass the query from knowledgebase & user.\n",
    "from langchain_openai import OpenAIÃŸ\n",
    "\n",
    "open_api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "llm = OpenAI(api_key=open_api_key, temperature=0.4, max_tokens=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1ea9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks.\"\n",
    "    \"Use the following pieces of retrieved context to answer\"\n",
    "    \"the question. If you don't know the ansewr, just say that you\"\n",
    "    \"don't know. Use three sentences maximum and keep the answer concise.\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"human\", f\"{input}\"),\n",
    "    \n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8420eb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_chain =  create_stuff_documents_chain(llm=llm, prompt=prompt)\n",
    "rag_chain = create_retrieval_chain(retriever,question_answer_chain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce01a183",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = rag_chain.invoke({\"input\": \"What is gigantism?\"})\n",
    "print(response[\"answer\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69512ba8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf14be2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1af85c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
